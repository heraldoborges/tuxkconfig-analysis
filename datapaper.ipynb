{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "def generate_kernel_stats_table(dataset_paths):\n",
    "    # Lista de versões correspondentes aos datasets\n",
    "    versions = [\"4.13\", \"4.15\", \"4.20\", \"5.0\", \"5.4\", \"5.7\", \"5.8\"]\n",
    "\n",
    "    # Valores de tempo médio fornecidos na tabela (em segundos)\n",
    "    avg_times = {\n",
    "        \"4.13\": 271,\n",
    "        \"4.15\": 263,\n",
    "        \"4.20\": 225,\n",
    "        \"5.0\": 225,\n",
    "        \"5.4\": 235,\n",
    "        \"5.7\": 235,\n",
    "        \"5.8\": 235\n",
    "    }\n",
    "\n",
    "    # Lista para armazenar os dados da tabela\n",
    "    table_data = []\n",
    "\n",
    "    # Alvos (targets) conhecidos do relatório\n",
    "    known_targets = [\"vmlinux\", \"GZIP-bzImage\", \"GZIP-vmlinux\", \"BZIP2-bzImage\", \"BZIP2-vmlinux\",\n",
    "                     \"LZMA-bzImage\", \"LZMA-vmlinux\", \"XZ-vmlinux\", \"bzImage\"]\n",
    "\n",
    "    for version, dataset_path in zip(versions, dataset_paths):\n",
    "        # Carregar o dataset\n",
    "        df = pd.read_pickle(dataset_path)\n",
    "\n",
    "        # Converter os valores de tamanho de bytes para MB (1 MB = 1024 * 1024 bytes)\n",
    "        for target in known_targets:\n",
    "            if target in df.columns:\n",
    "                df[target] = df[target] / (1024 * 1024)\n",
    "\n",
    "        # Número de configurações (linhas)\n",
    "        num_configs = len(df)\n",
    "\n",
    "        # Número de opções (colunas que não são alvos)\n",
    "        #option_columns = [col for col in df.columns if col not in known_targets] \n",
    "        option_columns = [col for col in df.columns]\n",
    "        num_options = len(option_columns)\n",
    "\n",
    "        #known_targets = [\"vmlinux\", \"GZIP-bzImage\", \"GZIP-vmlinux\", \"BZIP2-bzImage\", \"BZIP2-vmlinux\",\n",
    "        #                 \"LZMA-bzImage\", \"LZMA-vmlinux\", \"XZ-vmlinux\", \"bzImage\"]\n",
    "\n",
    "        # Tamanho mínimo e máximo do GZIP-bzImage (em MB)\n",
    "        min_size = df[\"vmlinux\"].min()\n",
    "        max_size = df[\"vmlinux\"].max()\n",
    "        min_max_size = f\"{min_size:.1f} - {max_size:.1f}\"\n",
    "\n",
    "        # Tempo médio (usando os valores fornecidos na tabela)\n",
    "        avg_time = avg_times[version]\n",
    "        print\n",
    "\n",
    "        # Adicionar os dados à tabela\n",
    "        table_data.append({\n",
    "            \"Version\": version,\n",
    "            \"Options\": f\"{num_options:,}\",\n",
    "            \"Configurations\": f\"{num_configs:,}\",\n",
    "            \"Min/Max Size (MB)\": min_max_size,\n",
    "            #\"Avg Time(s)\": avg_time\n",
    "        })\n",
    "\n",
    "    # Criar a tabela em formato Markdown\n",
    "    #table = \"| Version | Options | Configurations | Min/Max Size (MB) | Avg Time(s) |\\n\"\n",
    "    table = \"| Version | Options | Configurations | Min/Max Size (MB) |\\n\"\n",
    "    #table += \"|---------|---------|----------------|-------------------|-------------|\\n\"\n",
    "    table += \"|---------|---------|----------------|-------------------|\\n\"\n",
    "    for row in table_data:\n",
    "        #table += f\"| {row['Version']} | {row['Options']} | {row['Configurations']} | {row['Min/Max Size (MB)']} | {row['Avg Time(s)']} |\\n\"\n",
    "        table += f\"| {row['Version']} | {row['Options']} | {row['Configurations']} | {row['Min/Max Size (MB)']} |\\n\"\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b20add",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = [\n",
    "    \"dataset_413.pkl\",\n",
    "    \"dataset_415.pkl\",\n",
    "    \"dataset_420.pkl\",\n",
    "    \"dataset_500.pkl\",  \n",
    "    \"dataset_504.pkl\",\n",
    "    \"dataset_507.pkl\",\n",
    "    \"dataset_508.pkl\"\n",
    "]\n",
    "\n",
    "table = generate_kernel_stats_table(dataset_paths)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c98c5f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2945f40a",
   "metadata": {},
   "source": [
    "## BOXPLOT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae376cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_binary_size_boxplot(dataset_paths, output_image_path=\"tuxkconfig_boxplot.png\"):\n",
    "    \"\"\"\n",
    "    Generate a boxplot of the binary size distribution (MB) for the vmlinux target\n",
    "    across Linux kernel versions 4.13 to 5.8, similar to the provided figure.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset_paths (list): List of paths to the dataset files (.pkl format).\n",
    "    - output_image_path (str): Path to save the generated boxplot image (default: 'tuxkconfig_boxplot.png').\n",
    "    \n",
    "    Returns:\n",
    "    - Displays the boxplot in the notebook and saves it as an image.\n",
    "    \"\"\"\n",
    "    # Define the versions corresponding to the datasets\n",
    "    versions = [\"4.13\", \"4.15\", \"4.20\", \"5.0\", \"5.4\", \"5.7\", \"5.8\"]\n",
    "        \n",
    "    all_data = []\n",
    "    \n",
    "    # Load each dataset and extract the vmlinux sizes\n",
    "    for version, dataset_path in zip(versions, dataset_paths):\n",
    "        df = pd.read_pickle(dataset_path)\n",
    "        \n",
    "        # Convert vmlinux sizes from bytes to MB (1 MB = 1024 * 1024 bytes)\n",
    "        df[\"vmlinux\"] = df[\"vmlinux\"] / (1024 * 1024)\n",
    "        df[\"Version\"] = version\n",
    "        \n",
    "        # Append the vmlinux sizes and version to the combined data\n",
    "        all_data.append(df[[\"Version\", \"vmlinux\"]])\n",
    "    \n",
    "    \n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Generate the boxplot using seaborn\n",
    "    sns.boxplot(x=\"Version\", y=\"vmlinux\", data=combined_df, color=\"lightgray\", \n",
    "                medianprops={\"color\": \"orange\", \"linewidth\": 2}, \n",
    "                flierprops={\"marker\": \"o\", \"markersize\": 5, \"markerfacecolor\": \"black\", \"markeredgecolor\": \"black\"})\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(\"Boxplot of binary size distribution (MB) across versions 4.13 to 5.8.\", fontsize=12, pad=15)\n",
    "    plt.xlabel(\"Kernel Version\", fontsize=10)\n",
    "    plt.ylabel(\"Binary Size (MB)\", fontsize=10)\n",
    "    \n",
    "    plt.ylim(0, 1500)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_image_path, dpi=300, bbox_inches=\"tight\") #save     \n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dacf6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of paths to the datasets\n",
    "dataset_paths = [\n",
    "    \"dataset_413.pkl\",\n",
    "    \"dataset_415.pkl\",\n",
    "    \"dataset_420.pkl\",\n",
    "    \"dataset_500.pkl\",\n",
    "    \"dataset_504.pkl\",\n",
    "    \"dataset_507.pkl\",\n",
    "    \"dataset_508.pkl\"\n",
    "]\n",
    "\n",
    "# Generate and display the boxplot\n",
    "generate_binary_size_boxplot(dataset_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af87c5c",
   "metadata": {},
   "source": [
    "## 4.1 Performance Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# known targets to exclude from training features\n",
    "known_targets = [\"vmlinux\", \"GZIP-bzImage\", \"GZIP-vmlinux\", \"BZIP2-bzImage\", \"BZIP2-vmlinux\", \n",
    "                 \"LZMA-bzImage\", \"LZMA-vmlinux\", \"XZ-vmlinux\", \"bzImage\"]\n",
    "\n",
    "dataset = pd.read_pickle(\"dataset_500.pkl\")\n",
    "\n",
    "# Convert vmlinux sizes from bytes to MB \n",
    "dataset[\"vmlinux\"] = dataset[\"vmlinux\"] / (1024 * 1024)\n",
    "\n",
    "# Separate features (configuration options) and target (vmlinux size in MB)\n",
    "# Exclude known targets from the features\n",
    "X = dataset.drop(columns=known_targets, errors=\"ignore\")\n",
    "y = dataset[\"vmlinux\"]\n",
    "\n",
    "# Split the data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a simple linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate MAPE (Mean Absolute Percentage Error)\n",
    "mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "\n",
    "# Print the MAPE - MAPE: 57.29%\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d57bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.1 Performance Prediction - Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a02e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import openml\n",
    "import numpy as np\n",
    "\n",
    "# Fetch TuxKConfig v5.08 from OpenML\n",
    "dataset = openml.datasets.get_dataset(46739)\n",
    "X, y = dataset.get_data(target=\"Binary.Size\")\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate a simple linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate MAPE (Mean Absolute Percentage Error)\n",
    "mape = np.abs((predictions - y_test) / y_test).mean() * 100\n",
    "\n",
    "# Print the MAPE\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
